@article{fl-survey,
  author    = {Peter Kairouz and
               H. Brendan McMahan and
               Brendan Avent and
               Aur{\'{e}}lien Bellet and
               Mehdi Bennis and
               Arjun Nitin Bhagoji and
               Keith Bonawitz and
               Zachary Charles and
               Graham Cormode and
               Rachel Cummings and
               Rafael G. L. D'Oliveira and
               Salim El Rouayheb and
               David Evans and
               Josh Gardner and
               Zachary Garrett and
               Adri{\`{a}} Gasc{\'{o}}n and
               Badih Ghazi and
               Phillip B. Gibbons and
               Marco Gruteser and
               Za{\"{\i}}d Harchaoui and
               Chaoyang He and
               Lie He and
               Zhouyuan Huo and
               Ben Hutchinson and
               Justin Hsu and
               Martin Jaggi and
               Tara Javidi and
               Gauri Joshi and
               Mikhail Khodak and
               Jakub Konecn{\'{y}} and
               Aleksandra Korolova and
               Farinaz Koushanfar and
               Sanmi Koyejo and
               Tancr{\`{e}}de Lepoint and
               Yang Liu and
               Prateek Mittal and
               Mehryar Mohri and
               Richard Nock and
               Ayfer {\"{O}}zg{\"{u}}r and
               Rasmus Pagh and
               Mariana Raykova and
               Hang Qi and
               Daniel Ramage and
               Ramesh Raskar and
               Dawn Song and
               Weikang Song and
               Sebastian U. Stich and
               Ziteng Sun and
               Ananda Theertha Suresh and
               Florian Tram{\`{e}}r and
               Praneeth Vepakomma and
               Jianyu Wang and
               Li Xiong and
               Zheng Xu and
               Qiang Yang and
               Felix X. Yu and
               Han Yu and
               Sen Zhao},
  title     = {Advances and Open Problems in Federated Learning},
  journal   = {CoRR},
  volume    = {abs/1912.04977},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.04977},
  archivePrefix = {arXiv},
  eprint    = {1912.04977},
  timestamp = {Thu, 19 Nov 2020 08:56:34 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-04977.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{coop-sgd,
  author    = {Jianyu Wang and
               Gauri Joshi},
  title     = {Cooperative {SGD:} {A} unified Framework for the Design and Analysis
               of Communication-Efficient {SGD} Algorithms},
  journal   = {CoRR},
  volume    = {abs/1808.07576},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.07576},
  archivePrefix = {arXiv},
  eprint    = {1808.07576},
  timestamp = {Sun, 02 Sep 2018 15:01:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-07576.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bnn-chord,
  author={F. {Chao} and H. {Zhang} and X. {Du} and C. {Zhang}},
  booktitle={2011 7th International Conference on Wireless Communications, Networking and Mobile Computing}, 
  title={Improvement of Structured P2P Routing Algorithm Based on NN-CHORD}, 
  year={2011},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/wicom.2011.6040638}}


@inproceedings{8737602,
  author={G. {Neglia} and G. {Calbi} and D. {Towsley} and G. {Vardoyan}},
  booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications}, 
  title={The Role of Network Topology for Distributed Machine Learning}, 
  year={2019},
  volume={},
  number={},
  pages={2350-2358},
  doi={10.1109/INFOCOM.2019.8737602}}

@misc{marfoq2020throughputoptimal,
      title={Throughput-Optimal Topology Design for Cross-Silo Federated Learning}, 
      author={Othmane Marfoq and Chuan Xu and Giovanni Neglia and Richard Vidal},
      year={2020},
      eprint={2010.12229},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{hpc-carothers,
  author={M. {Mubarak} and C. D. {Carothers} and R. B. {Ross} and P. {Carns}},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Enabling Parallel Simulation of Large-Scale HPC Network Systems}, 
  year={2017},
  volume={28},
  number={1},
  pages={87-100},
  doi={10.1109/TPDS.2016.2543725}}

@article{towardsFL,
  author    = {Keith Bonawitz and
               Hubert Eichner and
               Wolfgang Grieskamp and
               Dzmitry Huba and
               Alex Ingerman and
               Vladimir Ivanov and
               Chlo{\'{e}} Kiddon and
               Jakub Konecn{\'{y}} and
               Stefano Mazzocchi and
               H. Brendan McMahan and
               Timon Van Overveldt and
               David Petrou and
               Daniel Ramage and
               Jason Roselander},
  title     = {Towards Federated Learning at Scale: System Design},
  journal   = {CoRR},
  volume    = {abs/1902.01046},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.01046},
  archivePrefix = {arXiv},
  eprint    = {1902.01046},
  timestamp = {Tue, 21 May 2019 18:03:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-01046.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pastry,
  added-at = {2011-07-23T18:45:48.000+0200},
  title = {astry: Scalable, distributed object location and routing for large-scale peer-to-peer systems},
  year = {2001},
  author = {Rowstron, A. and Druschel, P.},
  biburl = {https://www.bibsonomy.org/bibtex/29bbb095b449064373061c2d4416dfdbe/msteele},
  booktitle = {Middleware 2001},
  interhash = {1c64fb27b73cfcd52376141df3b192af}
}

@article{chord,
author = {Stoica, Ion and Morris, Robert and Liben-Nowell, David and Karger, David R. and Kaashoek, M. Frans and Dabek, Frank and Balakrishnan, Hari},
title = {Chord: A Scalable Peer-to-Peer Lookup Protocol for Internet Applications},
year = {2003},
issue_date = {February 2003},
publisher = {IEEE Press},
volume = {11},
number = {1},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2002.808407},
doi = {10.1109/TNET.2002.808407},
abstract = {A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.},
journal = {IEEE/ACM Trans. Netw.},
month = feb,
pages = {17–32},
numpages = {16},
keywords = {distributed scalable algorithms, lookup protocols, peer-to-peer networks}
}

@article{fat-trees,
author = {Leiserson, Charles E.},
title = {Fat-Trees:  Universal Networks for Hardware-Efficient Supercomputing},
year = {1985},
issue_date = {Oct. 1985},
publisher = {IEEE Computer Society},
address = {USA},
volume = {34},
number = {10},
issn = {0018-9340},
journal = {IEEE Trans. Comput.},
month = oct,
pages = {892–901},
numpages = {10}
}

@InProceedings{personal-private, title = {Personalized and Private Peer-to-Peer Machine Learning}, author = {Aurélien Bellet and Rachid Guerraoui and Mahsa Taziki and Marc Tommasi}, booktitle = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics}, pages = {473--481}, year = {2018}, editor = {Amos Storkey and Fernando Perez-Cruz}, volume = {84}, series = {Proceedings of Machine Learning Research}, month = {09--11 Apr}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v84/bellet18a/bellet18a.pdf}, url = { http://proceedings.mlr.press/v84/bellet18a.html }, abstract = {The rise of connected personal devices together with privacy concerns call for machine learning algorithms capable of leveraging the data of a large number of agents to learn personalized models under strong privacy requirements. In this paper, we introduce an efficient algorithm to address the above problem in a fully decentralized (peer-to-peer) and asynchronous fashion, with provable convergence rate. We show how to make the algorithm differentially private to protect against the disclosure of information about the personal datasets, and formally analyze the trade-off between utility and privacy. Our experiments show that our approach dramatically outperforms previous work in the non-private case, and that under privacy constraints, we can significantly improve over models learned in isolation.} } 

@misc{DecentralizedFederatedMultitaskLearning,
	title={Decentralized Federated Multi-Task Learning and System Design},
	url={https://www.zijianhu.com/project/dpa_sgd/},
	author={Chaoyang He and Tian Xie and Zhengyu Yang and Zijian Hu and Shuai Xi},
	year={2019}
}

@inproceedings{aegean,
	author = {Aksoy, Remzi Can and Kapritsos, Manos},
	title = {Aegean: Replication beyond the Client-Server Model},
	year = {2019},
	isbn = {9781450368735},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3341301.3359663},
	doi = {10.1145/3341301.3359663},
	abstract = {This paper presents Aegean, a new approach that allows fault-tolerant replication to be implemented beyond the confines of the client-server model. In today's computing, where services are rarely standalone, traditional replication protocols such as Primary-Backup, Paxos, and PBFT are not directly applicable, as they were designed for the client-server model. When services interact, these protocols run into a number of problems, affecting both correctness and performance. In this paper, we rethink the design of replication protocols in the presence of interactions between services and introduce new techniques that accommodate such interactions safely and efficiently. Our evaluation shows that a prototype implementation of Aegean not only ensures correctness in the presence of service interactions, but can further improve throughput by an order of magnitude.},
	booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
	pages = {385–398},
	numpages = {14},
	location = {Huntsville, Ontario, Canada},
	series = {SOSP '19}
}

@inbook{lynch1996distributedsyncghs,
  added-at = {2010-10-15T14:08:06.000+0200},
  asin = {1558603484},
  author = {Lynch, Nancy A.},
  biburl = {https://www.bibsonomy.org/bibtex/2b84b8bfd8cbf75ac670174df3c9640c4/schmitz},
  dewey = {005.276},
  ean = {9781558603486},
  edition = {1st},
  interhash = {0dbec4d56a79baaae3e4adbf7ac44d55},
  intrahash = {b84b8bfd8cbf75ac670174df3c9640c4},
  isbn = {1558603484},
  keywords = {computerscience top10},
  publisher = {Morgan Kaufmann},
  timestamp = {2010-10-15T14:08:06.000+0200},
  title = {Distributed Algorithms},
  url = {http://www.amazon.com/Distributed-Algorithms-Kaufmann-Management-Systems/dp/1558603484},
  year = 1996,
  pages = {63-70},
  chapter = {4.4}
}

@inbook{lynch1996distributedghs,
  added-at = {2010-10-15T14:08:06.000+0200},
  asin = {1558603484},
  author = {Lynch, Nancy A.},
  biburl = {https://www.bibsonomy.org/bibtex/2b84b8bfd8cbf75ac670174df3c9640c4/schmitz},
  dewey = {005.276},
  ean = {9781558603486},
  edition = {1st},
  interhash = {0dbec4d56a79baaae3e4adbf7ac44d55},
  intrahash = {b84b8bfd8cbf75ac670174df3c9640c4},
  isbn = {1558603484},
  keywords = {computerscience top10},
  publisher = {Morgan Kaufmann},
  timestamp = {2010-10-15T14:08:06.000+0200},
  title = {Distributed Algorithms},
  url = {http://www.amazon.com/Distributed-Algorithms-Kaufmann-Management-Systems/dp/1558603484},
  year = 1996,
  pages = {509-523},
  chapter = {15.5}
}

@article{matcha,
  author    = {Jianyu Wang and
               Anit Kumar Sahu and
               Zhouyi Yang and
               Gauri Joshi and
               Soummya Kar},
  title     = {{MATCHA:} Speeding Up Decentralized {SGD} via Matching Decomposition
               Sampling},
  journal   = {CoRR},
  volume    = {abs/1905.09435},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.09435},
  archivePrefix = {arXiv},
  eprint    = {1905.09435},
  timestamp = {Wed, 29 May 2019 11:27:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-09435.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vertical-paxos,
author = {Lamport, Leslie and Malkhi, Dahlia and Zhou, Lidong},
year = {2009},
month = {01},
pages = {312-313},
title = {Vertical Paxos and Primary-Backup Replication},
doi = {10.1145/1582716.1582783}
}

@inproceedings{federated-ai-microservices,
author = {Verma, Darshika and White, Graham and Mel, Geeth},
year = {2019},
month = {07},
pages = {20-27},
title = {Federated AI for the Enterprise: A Web Services Based Implementation},
doi = {10.1109/ICWS.2019.00016}
}

@inproceedings{elastic-ml-sagemaker,
author = {Liberty, Edo and Karnin, Zohar and Xiang, Bing and Rouesnel, Laurence and Coskun, Baris and Nallapati, Ramesh and Delgado, Julio and Sadoughi, Amir and Astashonok, Yury and Das, Piali and Balioglu, Can and Chakravarty, Saswata and Jha, Madhav and Gautier, Philip and Arpin, David and Januschowski, Tim and Flunkert, Valentin and Wang, Yuyang and Gasthaus, Jan and Stella, Lorenzo and Rangapuram, Syama and Salinas, David and Schelter, Sebastian and Smola, Alex},
title = {Elastic Machine Learning Algorithms in Amazon SageMaker},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3386126},
doi = {10.1145/3318464.3386126},
abstract = {There is a large body of research on scalable machine learning (ML). Nevertheless, training ML models on large, continuously evolving datasets is still a difficult and costly undertaking for many companies and institutions. We discuss such challenges and derive requirements for an industrial-scale ML platform. Next, we describe the computational model behind Amazon SageMaker, which is designed to meet such challenges. SageMaker is an ML platform provided as part of Amazon Web Services (AWS), and supports incremental training, resumable and elastic learning as well as automatic hyperparameter optimization. We detail how to adapt several popular ML algorithms to its computational model. Finally, we present an experimental evaluation on large datasets, comparing SageMaker to several scalable, JVM-based implementations of ML algorithms, which we significantly outperform with regard to computation time and cost.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {731–737},
numpages = {7},
keywords = {elastic machine learning, scalable machine learning},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@inproceedings{ai-5g-microservices,
  author={G. {Myoung Lee} and T. {Um} and J. K. {Choi}},
  booktitle={2018 ITU Kaleidoscope: Machine Learning for a 5G Future (ITU K)}, 
  title={AI AS A MICROSERVICE (AIMS) OVER 5G NETWORKS}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  doi={10.23919/ITU-WT.2018.8597704}}

@inbook{distributed-ml-overview,
author = {Galakatos, Alex and Crotty, Andrew and Kraska, Tim},
year = {2017},
month = {01},
pages = {1-6},
title = {Distributed Machine Learning},
doi = {10.1007/978-1-4899-7993-3_80647-1}
}

@inproceedings{p2p-nn-karger,
author = {Karger, David R. and Ruhl, Matthias},
title = {Finding Nearest Neighbors in Growth-Restricted Metrics},
year = {2002},
isbn = {1581134959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/509907.510013},
doi = {10.1145/509907.510013},
abstract = {Most research on nearest neighbor algorithms in the literature has been focused on the Euclidean case. In many practical search problems however, the underlying metric is non-Euclidean. Nearest neighbor algorithms for general metric spaces are quite weak, which motivates a search for other classes of metric spaces that can be tractably searched.In this paper, we develop an efficient dynamic data structure for nearest neighbor queries in growth-constrained metrics. These metrics satisfy the property that for any point q and number r the ratio between numbers of points in balls of radius 2r and r is bounded by a constant. Spaces of this kind may occur in networking applications, such as the Internet or Peer-to-peer networks, and vector quantization applications, where feature vectors fall into low-dimensional manifolds within high-dimensional vector spaces.},
booktitle = {Proceedings of the Thiry-Fourth Annual ACM Symposium on Theory of Computing},
pages = {741–750},
numpages = {10},
location = {Montreal, Quebec, Canada},
series = {STOC '02}
}

@phdthesis{Shah-phd,
title="Distributed Data Structures for Peer-to-peer Systems",
author="Gauri Shah",
school="Yale University",
month=may, year="2003",
address={New Haven, CT, USA},
} 

@ARTICLE {fat-trees-fault,
author = {F. Sem-Jacobsen and O. Lysne and J. Duato and T. Skeie},
journal = {IEEE Transactions on Computers},
title = {Dynamic Fault Tolerance in Fat Trees},
year = {2011},
volume = {60},
number = {04},
issn = {1557-9956},
pages = {508-525},
keywords = {fat trees;k-ary n-trees;dynamic fault tolerance;deterministic routing;adaptive routing.},
doi = {10.1109/TC.2010.97},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}


@article(skip-graphs,
title="Skip graphs",
author="James Aspnes and Gauri Shah",
journal="ACM Transactions on Algorithms",
month=nov,
year=2007,
volume=3,
number=4,
pages={37}
)
